

# **A Automated Normalization and Transformation (AN-T) for MINE-R: AI-Driven Normalization of Unreal Engine Game Data**

## **Section 1: The Automated Normalization and Transformation (AN-T) for MINE-R**

This report outlines a complete technical architecture for the *transformation* and *semantic enrichment* layer required by the MINE-R system. The existing pipeline successfully executes the extraction and loading (EL) of raw Unreal Engine DataTables from *Grounded 2* into JSON and a SQLite database. The challenge at hand is to design the transformation (T) layer.

This transformation is non-trivial; it is a semantic enrichment process. Raw game data files are structured for engine-level efficiency, not for player-facing intuition. Data is frequently nested, represented by engine-specific object paths (e.g., TSubclassOf\<UDamageType\> DamageType), or implied by "flavor text". The objective is to translate this developer-centric data into a player-centric, normalized, and relational format suitable for powering a game wiki.

The proposed solution is the **Automated Normalization and Transformation (AN-T)**, a modular, multi-phase system designed to sit on top of the MINE-R. This pipeline intelligently blends high-speed deterministic rules for "ground truth" data, statistical heuristics for "fuzzy" data, and advanced Natural Language Understanding (NLU) models for "ambiguous" data. This hybrid AI philosophy ensures accuracy, performance, and cost-effectiveness.

### **1.1 Architectural Overview**

The AN-T is architected as a 4-phase Python-based system. Each phase processes the data and passes its enriched output to the next, progressively building a complete, normalized data model.

1. **Phase 1: Deterministic Baseline:** This phase uses high-speed, 100% accurate methods (e.g., regular expressions, static mappers) to extract explicit "ground truth" data. This includes parsing item classes and damage types from Unreal object paths, extracting simple key-value stats (e.g., Durability), and mapping engine enums (e.g., EItemSlot::Head) to human-readable strings.  
2. **Phase 2: Heuristic & Clustering Inference:** This phase addresses "fuzzy" grouping problems, primarily the identification of armor sets (Goal 3). It uses a combination of rapid heuristic-based string matching and robust semantic clustering (via sentence-transformers and HDBSCAN) to group items like "Acorn Mask," "Acorn Plate," and "Acorn Greaves" into a single "Acorn Armor Set" entity.  
3. **Phase 3: AI-Powered NLU Parsing:** This phase acts as the "heavy lifter" for NLU, deploying a Generative AI model (Google Gemini) to handle tasks that elude the first two phases. This includes:  
   * **Classification:** Assigning categories (e.g., Light, Medium, Heavy) to items that lack explicit data.  
   * **Extraction:** Parsing stats from unstructured text blobs (e.g., "Defense... Upper Body: 15.00").  
   * **Canonicalization:** Mapping ambiguous perk descriptions (e.g., "Run faster.") to their canonical StatusEffect IDs (e.g., TheQuickness).  
4. **Phase 4: Semantic Normalization & Output:** The final phase takes the fully enriched data from Phase 3 and formats it into a final, relational ontology. This output will be generated as both SQL-ready objects for direct database insertion and as JSON-LD (JSON for Linked Data), which semantically describes the relationships between entities (e.g., item:acorn\_mask isPartOf set:acorn\_armor).

### **1.2 Data Flow & Integration with MINE-R**

The AN-T is designed as a new Python script (enrich.py) that seamlessly integrates with the existing MINE-R process.

* **Input:** The raw JSON files or a raw, non-normalized table in the SQLite database generated by MINE-R.  
* **Process:** The enrich.py orchestrator script will:  
  1. Load the raw item data.  
  2. Execute the 4-phase enrichment process on each item.  
  3. Cache the results of the expensive AI-driven (Phase 3\) operations to ensure efficient re-runs.  
  4. Store the final, enriched, and relational data models in new, normalized tables within the SQLite database.  
* **Output:** A set of Pydantic models (or simple dictionaries) representing the clean data, which are then used to generate INSERT or UPDATE statements for the normalized wiki database schema.

### **1.3 The Hybrid AI Philosophy: Deterministic-First, AI-Fallback**

A core principle of this architecture is the "deterministic-first, AI-fallback" model. A generative AI should not be tasked with work that a simple regular expression can perform. AI is computationally expensive, non-deterministic, and comparatively slow; regex is cheap, 100% accurate, and instantaneous.

The raw data from MINE-R originates from Unreal Engine DataTables. Unreal Engine is a heavily object-oriented C++ framework. Consequently, much of the critical data (item class, damage type) is not "missing" but is *embedded in the object path strings* that reference other game assets.

For example, a weapon's JSON might have a field like:  
"DamageType": "/Game/Blueprints/Damage/DamageType\_Slashing.DamageType\_Slashing\_C"  
A naive AI-only approach would ignore this path and attempt to *infer* the damage type by reading the item's description ("A sharp blade..."). This is unreliable. The AN-T approach, by contrast, establishes a rule (Phase 1\) to parse this string *first*. This is 100% reliable.

The AI (Phase 3\) is then reserved as a fallback. Only if the DamageType field is null or the regex fails will the pipeline escalate the task to the NLU model. This hybrid methodology ensures maximum accuracy, performance, and cost-efficiency, leveraging each tool for its specific strength.

## **Section 2: Phase 1: Deterministic Foundations (Rules, Regex, & Mappers)**

This initial phase constructs the immutable, high-confidence baseline for all item data. It is the fastest and most reliable component of the pipeline, designed to solve Goals 4 and 5 (Item/Damage Class) and parts of Goal 1 (Core Stats) before any complex processing is attempted.

### **2.1 Task: Parsing Unreal Object Paths**

As established in Section 1.3, the Unreal object path is a primary source of structured data. A library of Python-based regular expressions will be used to parse these paths.

Implementation (Goal 5: Damage Type):  
The JSON output for a weapon will likely reference a DamageType object.

* **Input JSON Field:** "BaseDamageType": "/Game/Blueprints/Damage/DamageType\_Slashing.DamageType\_Slashing\_C"  
* **Python Regex:**  
  Python  
  import re  
  DAMAGE\_TYPE\_REGEX \= re.compile(r'DamageType\_(\\w+)')

  def parse\_damage\_type(path\_string: str) \-\> str | None:  
      if not path\_string:  
          return None  
      match \= DAMAGE\_TYPE\_REGEX.search(path\_string)  
      return match.group(1).capitalize() if match else None

* **Output:** "Slashing"

Implementation (Goal 4: Armor Class):  
The object path of the item itself often reveals its class, as assets are typically organized in a logical folder structure.

* **Input JSON Field:** "ObjectPath": "/Game/Items/Armor/Heavy/BP\_AntlionHelmet.BP\_AntlionHelmet\_C"  
* **Python Regex:**  
  Python  
  ARMOR\_CLASS\_REGEX \= re.compile(r'/Armor/(Light|Medium|Heavy)/')

  def parse\_armor\_class(path\_string: str) \-\> str | None:  
      if not path\_string:  
          return None  
      match \= ARMOR\_CLASS\_REGEX.search(path\_string)  
      return match.group(1).capitalize() if match else None

* **Output:** "Heavy"  
* This deterministic classification is supported by game data analysis, which links armor types like "Heavy" to specific in-game stats, such as a 9% stamina cost increase per piece, or a 75% total increase for a full set. This regex provides a direct path to this classification.

### **2.2 Task: Extracting Simple, Known-Key Stats**

Many core stats (Goal 1\) will be simple, first-level key-value pairs in the JSON. This is a trivial but necessary extraction step.

* **Implementation:** A simple Python function will iterate through a known list of "clean" keys and extract their values.  
  Python  
  KNOWN\_SIMPLE\_STATS \=

  def get\_simple\_stats(item\_json: dict) \-\> dict:  
      stats \= {}  
      for key in KNOWN\_SIMPLE\_STATS:  
          if key in item\_json:  
              stats\[key\] \= item\_json\[key\]  
      return stats

* This will successfully capture data like "Durability": 80.0.

### **2.3 Task: Building Static Mappers (Enums)**

Game data frequently uses enumerations (enums) for fixed values (e.g., EItemSlot, EArmorWeight). The JSON export will contain the string representation of that enum (e.g., "EItemSlot::Head"). Static Python dictionaries will be used to map these to human-readable wiki strings.

* **Implementation:**  
  Python  
  ARMOR\_SLOT\_MAP \= {  
      "EItemSlot::Head": "Head",  
      "EItemSlot::Chest": "Upper Body",  
      "EKey::Legs": "Lower Body", \# Example of inconsistent enum naming  
      "EItemSlot::Accessory": "Accessory",  
      \#... to be populated as new enums are discovered  
  }

  def map\_item\_slot(enum\_string: str) \-\> str:  
      return ARMOR\_SLOT\_MAP.get(enum\_string, "Unknown Slot")

This deterministic phase builds a strong, reliable foundation. Any field that is successfully populated by Phase 1 (e.g., item\_class, slot) will be *locked* and *not* sent to the AI in Phase 3, preserving accuracy and saving resources.

## **Section 3: Phase 2: Inferring Implicit Sets & Classes (Heuristics & Clustering)**

This phase addresses the critical and complex **Goal 3: Armor Set Identification**. The challenge is that set membership is *implicit*. The data provides a list of individual items (e.g., "Nightstalker Helm," "Nightstalker Vest"), but not the "Armor Set" entity that groups them. This is a grouping problem for which we will evaluate two primary methods, ultimately recommending a hybrid of both.

### **3.1 Approach A: Heuristic Grouping with Fuzzy String Matching**

This approach assumes that items in a set follow a consistent naming convention, typically \`\` (e.g., "Acorn Mask," "Acorn Plate").

* **Methodology:** We use a fuzzy string matching algorithm to score the similarity between item names. The Python fuzzywuzzy library is well-suited for this. Specifically, the token\_set\_ratio function is ideal. It tokenizes each string, ignores word order, and finds the similarity of the common tokens, making it robust to variations like "Acorn Mask" vs. "Plate of the Acorn."  
* **Implementation:**  
  1. Create a list of all items classified as "Armor" in Phase 1\.  
  2. Iterate through this list, comparing each item to every other item using fuzz.token\_set\_ratio().  
  3. Group all items that have a similarity-of-set ratio above a certain threshold (e.g., 90\) into a *provisional set*.  
* **Example:**  
  * fuzz.token\_set\_ratio("Acorn Mask", "Acorn Plate") \-\> 100\. (Tokens {"Acorn"} are identical).  
  * fuzz.token\_set\_ratio("Nightstalker Helm", "Nightstalker Vest") \-\> 100\. (Tokens {"Nightstalker"} are identical).  
  * fuzz.token\_set\_ratio("Acorn Mask", "Spider Helm") \-\> \~40. (Tokens {"Mask"} vs {"Spider", "Helm"} are dissimilar).  
* **Pros:** Extremely fast, simple to implement, and correctly handles the majority of standard sets.  
* **Cons:** This method is brittle. It can be easily broken by non-standard names (e.g., a set named "Helm of the Sage" and "Robes of the Wise"). It will also incorrectly group items like "Rotten Acorn Mask" with the main set, as "Rotten" is just another token. This brittleness is a known problem, as even public wikis struggle to correctly identify set membership for individual or rotten pieces.

### **3.2 Approach B: Semantic Clustering with Text Embeddings (Recommended)**

This is a modern, robust, AI-driven approach that overcomes the limitations of syntactic matching. Instead of comparing *strings*, we compare the *semantic meaning* of item names, which can group non-obviously named items and correctly separate "Rotten" items.

* **Methodology:** We will use sentence-transformers, a Python framework for state-of-the-art text embeddings.  
* **Implementation:**  
  1. **Embed:** For each armor item, create a "semantic document." A simple concatenation like item\_name \+ ". " \+ item\_description is a good start. Pass this document to a pre-trained sentence-transformers model (e.g., all-MiniLM-L6-v2) to generate a high-dimensional vector (embedding) that captures the item's *meaning*.  
  2. **Cluster:** We now have a list of vectors, one for each item. We must cluster these vectors.  
  3. **Algorithm Choice (HDBSCAN vs. K-Means):** The correct algorithm choice is HDBSCAN. K-Means is a poor fit because it requires us to specify the number of clusters (k) in advance, and we do not know how many armor sets exist. HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise) is a density-based algorithm that *automatically* finds the optimal number of clusters.  
  4. **Critical Advantage:** HDBSCAN's most powerful feature for this use case is its ability to identify *outliers* (noise points). In our problem, an "outlier" is an item that doesn't semantically belong to any other cluster. This perfectly maps to the "Individual Armor Pieces" (e.g., "Gas Mask," "Aphid Slippers") that are not part of a set. HDBSCAN will therefore *simultaneously* group the sets and *identify* the individual pieces, solving two problems at once.  
* **Pros:** Extremely robust. Groups items by *semantic concept*, not just shared words. Can group "Helm of the Sage" and "Robes of the Wise" if their descriptions are similar. Correctly identifies "Rotten" items as a separate cluster from their "non-Rotten" counterparts. Automatically discovers the number of sets and isolates unique items.  
* **Cons:** More computationally expensive (a one-time cost), and requires installing machine learning libraries (sentence-transformers, hdbscan).

### **3.3 AN-T Recommendation: A Hybrid of Both Approaches**

The optimal solution is a hybrid of 3.1 and 3.2, designed for maximum performance and accuracy.

1. **Step 1 (Fast Heuristic):** First, run the fuzzywuzzy token\_set\_ratio approach (3.1) on all armor. This will successfully group 80-90% of all items into high-confidence *provisional sets*.  
2. **Step 2 (Robust Clustering):** Take all remaining items—the "singles" and small, low-confidence groups—and run them through the more expensive HDBSCAN semantic clustering pipeline (3.2). This will find the non-obvious sets and identify the true individual items.  
3. Step 3 (Set Naming): Once a cluster is formed, a canonical set name must be chosen. This can be done by:  
   a. Heuristically: Finding the longest common substring among all item names in the cluster (e.g., "Acorn").  
   b. AI-Powered: Sending the list of item names (e.g., \["Nightstalker Helm", "Nightstalker Vest"\]) to Gemini in Phase 3 with the prompt: "What is the common set name for these items?"  
4. **Step 4 (Validation):** This process creates a canonical ArmorSets table. The armor\_set\_id is then assigned as a foreign key to each item in the Items table.

This hybrid approach provides a fast, accurate, and robust solution to the complex problem of implicit set identification.

## **Section 4: Phase 3: Advanced NLU with AI-Powered Parsing**

This phase tackles the most complex "fuzzy" data challenges: ambiguity, missing data, and unstructured text. It uses a Generative AI model (Google Gemini) as a fallback for tasks that Phase 1 could not deterministically solve. All AI calls will be routed through a central module that implements caching to prevent redundant API calls.

### **4.1 Task: Classifying Ambiguous Entities (Goals 4, 5, 6\)**

* **Problem:** The Phase 1 regex parsers (Section 2.1) fail. An item's ObjectPath is generic, or a field like EArmorWeight is missing. We are left with an item (e.g., "Antlion Plate") that we *know* is armor, but we do not know its class (Light, Medium, or Heavy).  
* **Solution:** We use Gemini as a *classifier*. We provide it with the item's JSON (name, description, and any known stats) and ask it to choose from a constrained list of options.  
* **Example (Goal 4: Armor Class):**  
  * **Input:** The item's JSON, which lacks a clear armor\_weight enum. We *have* parsed its stats, such as a high stamina cost.  
  * **Context:** {"Name": "Antlion Plate", "Description": "Thick, heat-resistant chitin...", "StaminaCost": 9.0}.  
  * **AI Task:** Classify this item as Light, Medium, or Heavy. The high stamina cost is a strong signal for "Heavy". The AI, trained on *Grounded* wiki data (or simply good at inference), can make this connection.  
  * **AI Call:** We will use Gemini's **Structured Output** feature to *force* the model to respond *only* with a valid enum value. This is critical for data integrity.

### **4.2 Task: Extracting Stats from Unstructured Text (Goal 1\)**

* **Problem:** Stats are not always clean key-value pairs. As seen in the *Grounded* wiki, they are often buried in unstructured text blobs, e.g.: "Defense, Head & Lower Body: 7.50 Upper Body: 15.00" or "Resistance, Head: 5.00% Upper Body: 9.00% Lower Body: 6.00%".  
* **Solution:** We use Gemini as an *entity extractor*.  
* **Example (Goal 1: Stats):**  
  * **Input:** The string "Defense, Head & Lower Body: 7.50 Upper Body: 15.00".  
  * **AI Task:** Extract the Defense (DR) values and map them to their respective slots.  
  * **AI Call:** We will use a Pydantic schema that defines the desired JSON *shape*, such as {"head\_dr": 7.50, "body\_dr": 15.00, "legs\_dr": 7.50}. The AI's task is to populate this "form."

### **4.3 Task: Canonicalizing Effects and Perks (Goal 2\)**

* **Problem:** This is the most complex NLU task. An item's JSON may list a perk by its name (e.g., "Buggy Criticals") or imply it with flavor text (e.g., "Run faster."). The goal is to map this ambiguous string to a *canonical*, *unique* StatusEffect ID (e.g., TheQuickness) from the game's StatusEffects DataTable.  
* **Solution:** We use Gemini as a *semantic-matching* or *classification* engine.  
* **Implementation:**  
  1. **Ground Truth:** First, we must export the StatusEffects DataTable (or scrape the wiki's Lua module) to create a "ground truth" list of all canonical effects. This list will look like: \`\`.  
  2. **AI Task:** The AI will be given the item's perk name and/or description (e.g., "Buggy Criticals") and this *entire canonical list*.  
  3. **AI Prompt:** "You are a game data expert. Review the item's perk. Find the *single best match* from the provided and return *only* its id."  
* **Example (Goal 2: Effects):**  
  * **Input:** Item Json: {"EffectName": "Buggy Criticals", "EffectDescription": "Your Buggy has increased critical hit chance."}.  
  * **Canonical List:** \`\`  
  * **AI Output:** "buggy-criticals"  
  * This maps the item's perk to a foreign key in the StatusEffects table, achieving perfect normalization for a set bonus, armor perk, or sleek effect.

## **Section 5: Practical Implementation: Gemini Structured Output**

This section provides the core technical implementation plan for Phase 3\. We will use Google's Gemini API. For these tasks, **Structured Output** is the preferred method over Function Calling. Function Calling is designed for an agent to decide *which tool to use*. Structured Output is designed to *force the model's final response to conform to a specific JSON schema*, which is exactly what is required for data extraction and normalization.

We will use the Python google-generativeai library and define our schemas using Pydantic, which is now natively supported.

### **5.1 Defining Pydantic Schemas for Extraction**

Pydantic models are used to define the *exact* output structure. Gemini will be forced to populate an instance of this model, guaranteeing syntactically valid and type-safe JSON.

Schema 1: ParsedArmorStats (for Task 4.2)  
This schema will parse the unstructured text blobs from.

Python

from pydantic import BaseModel, Field  
from typing import Optional

class ParsedArmorStats(BaseModel):  
    """  
    Schema for armor stats extracted from unstructured text.  
    All values are optional, as not all text blobs contain all stats.  
    """  
    head\_defense: Optional\[float\] \= Field(  
        None, description="The Defense (DR) value for the Head slot."  
    )  
    body\_defense: Optional\[float\] \= Field(  
        None, description="The Defense (DR) value for the Upper Body slot."  
    )  
    legs\_defense: Optional\[float\] \= Field(  
        None, description="The Defense (DR) value for the Lower Body slot."  
    )  
    head\_resistance: Optional\[float\] \= Field(  
        None, description="The Resistance percentage for the Head slot."  
    )  
    body\_resistance: Optional\[float\] \= Field(  
        None, description="The Resistance percentage for the Upper Body slot."  
    )  
    legs\_resistance: Optional\[float\] \= Field(  
        None, description="The Resistance percentage for the Lower Body slot."  
    )

Schema 2: ParsedItemClassification (for Task 4.1)  
This schema classifies items where Phase 1 failed. It uses Enums to ensure the output is one of a few allowed values.

Python

from enum import Enum

class ArmorWeight(str, Enum):  
    LIGHT \= "Light"  
    MEDIUM \= "Medium"  
    HEAVY \= "Heavy"  
    UNKNOWN \= "Unknown"

class WeaponHand(str, Enum):  
    ONE\_HANDED \= "1-Handed"  
    TWO\_HANDED \= "2-Handed"  
    UNKNOWN \= "Unknown"

class ParsedItemClassification(BaseModel):  
    """  
    Schema for classifying an item's core class  
    when deterministic methods fail.  
    """  
    armor\_weight: Optional \= Field(  
        None, description="The armor weight class (Light, Medium, Heavy)."  
    )  
    weapon\_hand: Optional \= Field(  
        None, description="The number of hands required for a weapon."  
    )  
    \# Additional classifications (e.g., weapon type) can be added here.

### **5.2 Crafting Few-Shot Prompts for Gemini**

The prompt must be engineered to provide context, examples (few-shot prompting), and the specific task.

**Prompt 1 (Stat Extraction for ParsedArmorStats)**

Code snippet

You are an expert data extraction bot for the game Grounded 2\.  
Your task is to parse unstructured text blobs from item data  
and extract the specific armor stats, conforming to the provided  
Pydantic schema.

If a value is not present, leave it as null.  
Pay close attention to the slot (Head, Upper Body, Lower Body).

Input: "Defense, Head & Lower Body: 7.50 Upper Body: 15.00"  
Output: {  
  "head\_defense": 7.50,  
  "body\_defense": 15.00,  
  "legs\_defense": 7.50  
}

Input: "Resistance, Head: 5.00% Upper Body: 9.00% Lower Body: 6.00%"  
Output: {  
  "head\_resistance": 5.00,  
  "body\_resistance": 9.00,  
  "legs\_resistance": 6.00  
}

Text to Parse:  
"Defense, Head: 7.50 Upper Body: 15.00, Resistance, Head: 5.00% Upper Body: 9.00% Lower Body: 6.00%"

Output:

**Python Call (using google-generativeai):**

Python

import google.generativeai as genai

\#... (API Key setup)...  
model \= genai.GenerativeModel(model\_name='gemini-1.5-pro-latest')

response \= model.generate\_content(  
    prompt\_1\_text,  
    generation\_config=genai.GenerationConfig(  
        response\_schema=ParsedArmorStats  
    )  
)

\# The 'response.text' will be a \*guaranteed valid\* JSON  
\# string that can be loaded into the ParsedArmorStats Pydantic model.

Prompt 2 (Effect Canonicalization for Task 4.3)  
This task is better solved with a simple text response, as the output is just a single string ID.

Code snippet

You are a semantic mapping expert for the game Grounded 2\.  
Your task is to map an item's perk or effect text to the  
\*canonical StatusEffect ID\* from the provided list.  
Respond with the matching \`id\` string ONLY. If no match is found,  
respond with "NULL".

{  
  "effects":"},  
    {"id": "trickle-regen", "name": "Trickle Regen", "desc": "Regenerate health over time."},  
    {"id": "buggy-criticals", "name": "Buggy Criticals", "desc": "Your Buggy has increased critical hit chance."},  
    {"id": "venomous-dasher", "name": "Venomous Dasher", "desc": "Dash strikes using dual weapons inflict venom buildup on hit."},  
    {"id": "increase-attack-damage", "name": "+Attack", "desc": "Increases damage of all attacks by 25%."}  
  \]  
}

Item: {"PerkName": "Quickness", "PerkDescription": "Allows you to run faster."}  
Output: the-quickness

Item: {"PerkName": "Sleek", "PerkDescription": "Dash strikes inflict venom."}  
Output: venomous-dasher

Item:  
{  
  "Name": "Nightstalker Helm",  
  "PerkName": "Buggy Criticals",  
  "PerkDescription": "Your Buggy has increased critical hit chance."  
}

Output:

Expected AI Output:  
buggy-criticals

### **5.3 Summary Table: AI-Driven Parsing Strategy**

This table summarizes the AN-T's hybrid strategy for each goal.

| Goal | Task | Input Data | Method | Phase | Gemini Schema/Tool |
| :---- | :---- | :---- | :---- | :---- | :---- |
| 1, 4 | **Classify Armor Weight** | Item JSON (Name, Desc, Stats) | Classification (Fallback) | 3 | ParsedItemClassification (Pydantic) |
| 4 | **Classify Weapon Type** | Item JSON (Name, Desc) | Classification (Fallback) | 3 | ParsedItemClassification (Pydantic) |
| 5 | **Classify Damage Type** | BaseDamageType (Object Path) | Regex | 1 | N/A |
| 5 | **Classify Damage Type** | Item JSON (Name, Desc) | Classification (Fallback) | 3 | Pydantic w/ DamageType Enum |
| 1 | **Extract Simple Stats** | JSON (e.g., "Durability": 80\) | Direct Key-Value | 1 | N/A |
| 1 | **Extract Complex Stats** | Unstructured string (e.g., "DR: 15.00") | Extraction | 3 | ParsedArmorStats (Pydantic) |
| 2 | **Map Perk to Effect** | Item JSON (Perk Name, Desc) | Semantic Matching | 3 | Constrained Text Response (Prompt 2\) |
| 3 | **Identify Armor Set** | Item Names (e.g., "Acorn Mask") | Fuzzy Match \+ Clustering | 2 | N/A (Uses fuzzywuzzy & HDBSCAN) |
| 3 | **Name Armor Set** | List of Item Names in Cluster | Extraction (Optional) | 3 | {"set\_name": "Acorn"} |
| 6 | **Tagging (General)** | Item JSON (all fields) | Classification | 3 | Pydantic w/ various Tag Enums |

## **Section 6: Phase 4: Defining a Wiki-Ready Data Ontology (SQL & JSON-LD)**

The final phase involves defining the target data structure. The enriched output from the AN-T must be "schema-ready" for the wiki's database. We will define both the normalized SQL schema and a more expressive JSON-LD intermediate.

### **6.1 Proposed Normalized SQL Schema**

The existing MINE-R schema (Items, ArmorSets, StatusEffects, Recipes) is a good foundation. The AN-T will populate this schema and the new join tables required for full normalization. The following ALTER and CREATE statements will be required to store the newly inferred data.

SQL

/\* Update existing Items table to store inferred classifications \*/  
ALTER TABLE Items ADD COLUMN armor\_set\_id INTEGER REFERENCES ArmorSets(set\_id);  
ALTER TABLE Items ADD COLUMN item\_class TEXT; /\* 'Heavy Armor', '1-Handed Sword', etc. \*/  
ALTER TABLE Items ADD COLUMN slot TEXT; /\* 'Head', 'Upper Body', 'Accessory', etc. \*/  
ALTER TABLE Items ADD COLUMN dr\_base REAL;  
ALTER TABLE Items ADD COLUMN resistance\_base REAL;  
ALTER TABLE Items ADD COLUMN durability REAL;

/\* Create/Update ArmorSets table, populated by Phase 2 \*/  
CREATE TABLE IF NOT EXISTS ArmorSets (  
    set\_id INTEGER PRIMARY KEY AUTOINCREMENT,  
    set\_name TEXT UNIQUE NOT NULL, /\* e.g., 'Acorn Armor Set' \*/  
    set\_bonus\_effect\_id TEXT REFERENCES StatusEffects(effect\_id) /\* Populated by Phase 3 \*/  
);

/\* Create new join table for item damage types (for weapons) \*/  
CREATE TABLE IF NOT EXISTS Item\_DamageTypes (  
    item\_id TEXT NOT NULL REFERENCES Items(item\_id),  
    damage\_type TEXT NOT NULL, /\* 'Slashing', 'Stabbing', 'Spicy', 'Fresh' \*/  
    is\_base\_type BOOLEAN DEFAULT 1, /\* 1 for base, 0 for augment \*/  
    PRIMARY KEY (item\_id, damage\_type)  
);

/\* Create new join table for item effects (armor perks, sleek bonuses) \*/  
CREATE TABLE IF NOT EXISTS Item\_Effects (  
    item\_id TEXT NOT NULL REFERENCES Items(item\_id),  
    effect\_id TEXT NOT NULL REFERENCES StatusEffects(effect\_id),  
    source TEXT NOT NULL, /\* 'Base', 'Sleek', 'Set Bonus' \*/  
    PRIMARY KEY (item\_id, effect\_id, source)  
);

/\* StatusEffects table (populated from JSON or S21) \*/  
CREATE TABLE IF NOT EXISTS StatusEffects (  
    effect\_id TEXT PRIMARY KEY, /\* e.g., 'the-quickness' \*/  
    name TEXT NOT NULL, /\* e.g., 'The Quickness' \*/  
    description TEXT, /\* e.g., 'Run faster.' \*/  
    category TEXT /\* 'positive', 'negative', 'armor\_set' \*/  
);

### **6.2 Generating JSON-LD as a Semantic Intermediate**

Before flattening the data into SQL, it is highly recommended to generate a JSON-LD (JSON for Linked Data) object as the final output of Phase 4\. JSON-LD is valid JSON, but it adds a @context that maps the data to a formal ontology. This creates a "knowledge graph" that explicitly defines the relationships (e.g., isPartOf) inferred by the pipeline.

We will use the schema.org vocabulary, which includes VideoGame and gameItem types, and extend it with a custom grounded: ontology for game-specific properties.

**Example Enriched JSON-LD Output (for Acorn Mask)**

JSON

{  
  "@context": {  
    "@vocab": "https://schema.org/",  
    "grounded": "https://grounded.wiki.gg/ontology\#",  
    "gameItem": "VideoGame/gameItem",  
    "isPartOf": "isPartOf",  
    "armorClass": "grounded:armorClass",  
    "armorSlot": "grounded:armorSlot",  
    "durability": "grounded:durability",  
    "defense": "grounded:defense",  
    "providesEffect": "grounded:providesEffect"  
  },  
  "@type": "gameItem",  
  "@id": "grounded:item:acorn\_mask",  
  "name": "Acorn Mask",  
  "description": "A crude helmet made from a tough acorn shell.",  
  "armorClass": "Medium",  
  "armorSlot": "Head",  
  "durability": 60.0,  
  "defense": 7.50,  
  "isPartOf": {  
    "@type": "grounded:ArmorSet",  
    "@id": "grounded:set:acorn\_armor",  
    "name": "Acorn Armor Set"  
  },  
  "providesEffect": \[  
    {  
      "@id": "grounded:effect:unnamed\_set\_bonus",  
      "name": "+Health",  
      "description": "Increases max health."  
    }  
  \]  
}

This single JSON-LD object contains *all* the inferred data (the armorClass, the armorSlot, and the isPartOf set relationship) in a structured, queryable, and machine-readable format. A simple parser can then read this object and populate all the normalized SQL tables ( Items, ArmorSets, Item\_Effects ) correctly.

## **Section 7: Recommended MINE-R Pipeline Integration & Script Edits**

This section provides the actionable plan to integrate the AN-T into the existing MINE-R codebase. This involves a new orchestration script, a module for AI interaction, and modifications to the database loader.

### **7.1 New Script: enrichment\_pipeline.py**

This new Python script will serve as the orchestrator for the 4-phase AN-T.

Python

import json  
import diskcache  
from gemini\_parser import GeminiParser  
from deterministic\_parser import DeterministicParser  
from set\_clusterer import SetClusterer  
from database\_loader import DatabaseLoader

\# Initialize a persistent cache for AI calls  
\# This prevents re-processing items that haven't changed  
ai\_cache \= diskcache.Cache('ai\_cache')  
gemini\_parser \= GeminiParser(api\_key="YOUR\_API\_KEY")  
deterministic\_parser \= DeterministicParser()  
set\_clusterer \= SetClusterer()  
db\_loader \= DatabaseLoader('wiki\_database.sqlite')

def enrich\_item(item\_json: dict, canonical\_effects: list) \-\> dict:  
    """  
    Runs a single item through the 4-Phase AN-T.  
    """  
    \# Create a unique, stable hash for the raw item  
    item\_hash \= hash(json.dumps(item\_json, sort\_keys=True))  
      
    \# Check cache first  
    cached\_result \= ai\_cache.get(item\_hash)  
    if cached\_result:  
        return cached\_result

    \# \--- PHASE 1: DETERMINISTIC \---  
    enriched\_item \= deterministic\_parser.parse(item\_json)

    \# \--- PHASE 3: AI ENRICHMENT (Fallbacks) \---  
    \# (Phase 2 is run in batch, see main())  
      
    \# Task 4.1: Classify if Phase 1 failed  
    if 'armor\_weight' not in enriched\_item:  
        enriched\_item \= gemini\_parser.classify\_item(enriched\_item)  
      
    \# Task 4.2: Extract complex stats  
    if 'unstructured\_stats\_blob' in enriched\_item:  
        stats \= gemini\_parser.extract\_stats(enriched\_item\['unstructured\_stats\_blob'\])  
        enriched\_item.update(stats)  
          
    \# Task 4.3: Canonicalize effects  
    if 'raw\_perk\_text' in enriched\_item:  
        effect\_id \= gemini\_parser.match\_effect(  
            enriched\_item\['raw\_perk\_text'\],   
            canonical\_effects  
        )  
        enriched\_item\['canonical\_effect\_id'\] \= effect\_id

    \# Cache the expensive result  
    ai\_cache.set(item\_hash, enriched\_item)  
    return enriched\_item

def main():  
    """  
    Main orchestration function for the AN-T.  
    """  
    \# 1\. Load raw data from MINE-R  
    raw\_items \= db\_loader.load\_raw\_items()  
    canonical\_effects \= db\_loader.load\_canonical\_effects() \# From S21

    \# 2\. \--- PHASE 1 & 3 (Batch) \---  
    \# Run Phase 1 & 3 AI enrichment on all items  
    enriched\_items \= \[  
        enrich\_item(item, canonical\_effects) for item in raw\_items  
    \]

    \# 3\. \--- PHASE 2 (Batch) \---  
    \# Run armor set clustering on the enriched items  
    armor\_items \= \[item for item in enriched\_items if item\['slot'\] in\]  
    set\_mappings \= set\_clusterer.cluster\_sets(armor\_items) \# Returns dict {item\_id: set\_id}  
      
    \# Update items with their new set\_id  
    for item in enriched\_items:  
        if item\['item\_id'\] in set\_mappings:  
            item\['armor\_set\_id'\] \= set\_mappings\[item\['item\_id'\]\]

    \# 4\. \--- PHASE 4 (Batch) \---  
    \# Generate final ontology and load into normalized DB  
    json\_ld\_outputs \= \[db\_loader.generate\_json\_ld(item) for item in enriched\_items\]  
      
    \# 5\. Load into new, normalized tables  
    db\_loader.load\_normalized\_data(json\_ld\_outputs)

if \_\_name\_\_ \== "\_\_main\_\_":  
    main()

### **7.2 New Module: gemini\_parser.py**

This module abstracts all interaction with the Gemini API, incorporating the Pydantic schemas and prompts from Section 5\.

Python

import google.generativeai as genai  
from pydantic\_schemas import ParsedArmorStats, ParsedItemClassification

class GeminiParser:  
    def \_\_init\_\_(self, api\_key: str):  
        genai.configure(api\_key=api\_key)  
        self.model \= genai.GenerativeModel(model\_name='gemini-1.5-pro-latest')

    def classify\_item(self, item\_json: dict) \-\> dict:  
        """  
        Calls Gemini with Structured Output to classify  
        an item's weight, hand, etc. (Task 4.1)  
        """  
        \#... (Build Prompt 2 from Section 5.2)...  
        prompt \= f"Classify the following item: {json.dumps(item\_json)}"  
          
        try:  
            response \= self.model.generate\_content(  
                prompt,  
                generation\_config=genai.GenerationConfig(  
                    response\_schema=ParsedItemClassification  
                )  
            )  
            \# Merge the classified data back into the item  
            classification\_data \= json.loads(response.text)  
            item\_json.update(classification\_data)  
        except Exception as e:  
            print(f"Error classifying item {item\_json.get('name')}: {e}")  
              
        return item\_json

    def extract\_stats(self, text\_blob: str) \-\> dict:  
        """  
        Calls Gemini with Structured Output to parse  
        unstructured stat text. (Task 4.2)  
        """  
        \#... (Use Prompt 1 from Section 5.2)...  
        prompt \= f"Parse the following text: {text\_blob}"  
          
        try:  
            response \= self.model.generate\_content(  
                prompt,  
                generation\_config=genai.GenerationConfig(  
                    response\_schema=ParsedArmorStats  
                )  
            )  
            return json.loads(response.text)  
        except Exception as e:  
            print(f"Error extracting stats: {e}")  
            return {}

    def match\_effect(self, perk\_text: str, canonical\_effects: list) \-\> str | None:  
        """  
        Calls Gemini to find the best semantic match for a perk. (Task 4.3)  
        """  
        \#... (Use Prompt 2 from Section 5.2)...  
        prompt \= "..." \# (Prompt 2 with perk\_text and canonical\_effects)  
          
        try:  
            response \= self.model.generate\_content(prompt)  
            return response.text.strip() if response.text.strip()\!= "NULL" else None  
        except Exception as e:  
            print(f"Error matching effect: {e}")  
            return None

### **7.3 Edits to Database Schema and Loader**

The final step is to modify the existing MINE-R database loader to populate the new, normalized schema defined in Section 6.1. The database\_loader.py script (referenced in main()) will need a new method, load\_normalized\_data, which takes the final JSON-LD (or enriched dictionary) and executes the INSERT statements with ON CONFLICT DO UPDATE to populate the Items, ArmorSets, Item\_Effects, and Item\_DamageTypes tables. This completes the pipeline, transforming MINE-R from a data extractor into a fully-fledged, AI-driven semantic analysis and normalization engine capable of automating the *Grounded 2* wiki.